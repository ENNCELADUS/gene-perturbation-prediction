\documentclass{article}


% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2023


% ready for submission
%\usepackage{neurips_2023}
\usepackage[final]{neurips_2023}

\makeatletter
\renewcommand{\@noticestring}{}
\makeatother

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2023}


% to compile a camera-ready version, add the [final] option, e.g.:
%     \usepackage[final]{neurips_2023}


% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2023}


\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}
\usepackage{algorithm}      % 提供 algorithm 环境
\usepackage{algpseudocode}  % 提供 algorithm 语法支持
\usepackage{algorithmicx}   % 提供 algorithm 扩展功能
\usepackage{multirow}

\usepackage{amssymb}    % 数学符号扩展
\usepackage{amsmath}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\title{From Transcriptome-wide Prediction to Target Gene Discovery: Improving Virtual Cell Models with scGPT}


% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.



\author{
	Anrui Wang \\
	2023533015 \\
	\texttt{wangar2023@shanghaitech.edu.cn}\\
	\And
	Jiawen Dai \\
	2023533132 \\
	\texttt{daijw2023@shanghaitech.edu.cn}\\
	\AND
	Yiting Qi \\
	2023533043 \\
	\texttt{qiyt2023@shanghaitech.edu.cn}\\
}


\begin{document}
	
	
	\maketitle
	
	
	\begin{abstract}
    Predicting cellular responses to genetic or drug perturbations is a fundamental challenge in computational biology, with significant implications for drug discovery and functional genomics. Traditional virtual cell modeling, exemplified by the Virtual Cell Challenge (VCC), formulates this task as transcriptome-wide regression. However, transcriptome-wide evaluation suffers from high dimensionality, noisy measurements, and metrics dominated by non-informative genes, limiting its biological interpretability. In this work, we reformulate the task as target gene identification, ranking candidate genes by their likelihood of being true perturbation targets. We implement a refined evaluation framework for the VCC benchmark, re-splitting 150 known gene perturbations into train, validation, and test sets, and assess the performance of STATE and scGPT models. Furthermore, we develop scGPT-based models tailored for target gene discovery and extend our evaluation to drug perturbations using the Tahoe-100M dataset. Our study highlights both the limitations of transcriptome-wide metrics and the promise of target-focused modeling, providing insights for more biologically meaningful virtual cell predictions.
	\end{abstract}
	
	
	\section{Introduction}

    \subsection{Background}

    Cells are the fundamental functional units of biological systems, whose states and behaviors are governed by complex regulatory mechanisms. Understanding how cellular transcriptomes respond to perturbations—such as gene knockouts or drug treatments—across different cell types and conditions is a central problem in biology and medicine.

    Although advances in single-cell RNA sequencing and CRISPR-based perturbation technologies have enabled large-scale measurement of transcriptional responses, systematic experimental exploration remains prohibitively expensive and limited in throughput. As a result, only a small fraction of all possible perturbations can be tested in practice.

    Early attempts to construct comprehensive “whole-cell” computational models date back to the late 1990s, but were constrained by sparse data, simplified biological assumptions, and limited computational resources. Recently, the availability of large-scale single-cell atlases, rich perturbation datasets, and modern machine learning methods has renewed interest in this direction. In particular, the concept of the AI Virtual Cell (AIVC) has been proposed as a data-driven framework capable of modeling and simulating cellular responses under diverse perturbations and conditions.

    Within this context, foundation models for single-cell data, such as scGPT, offer a promising avenue for learning transferable cellular representations and enabling predictive modeling of perturbation responses.

    \subsection{Problem Setting: Predicting Transcriptomic Responses to Perturbations}

    In the standard Virtual Cell Challenge (VCC) setting, the task is formulated as predicting transcriptomic responses to perturbations. Given an initial cellular state and a specified perturbation, such as a gene knockout or chemical treatment, the model is required to predict the resulting changes in gene expression induced by the perturbation.

    Formally, the input consists of a representation of the pre-perturbation cell state together with a perturbation descriptor, while the output is a high-dimensional vector capturing perturbation-induced gene expression changes across the transcriptome. This task is typically cast as a transcriptome-wide regression problem, where models are trained to minimize errors between predicted and observed expression changes.

    Evaluation in this setting commonly relies on correlation-based or mean squared error (MSE)–based metrics, which aggregate prediction errors across all genes.

    \subsection{Motivation for Downstream Evaluation}

    While transcriptome-wide perturbation prediction has become a standard proxy task for evaluating virtual cell models, it does not directly reflect how such models are ultimately used in practice. In many biological and biomedical applications, the primary interest lies in identifying the key genes or pathways driving a perturbation-induced cellular response, rather than accurately predicting the full transcriptome. This observation motivates us to consider downstream tasks that more directly assess the biological utility of virtual cell models.

    \subsection{Reformulating the Task: Target Gene Identification as a Downstream Evaluation}

    We reformulate the evaluation of virtual cell models as a downstream target gene identification task. Given a population of cells subjected to a known perturbation, the model is required to assign scores to candidate genes and rank them by their likelihood of being true perturbation targets. This formulation evaluates whether the model can correctly prioritize biologically relevant genes whose perturbation induces meaningful cellular changes.

    Compared to transcriptome-wide regression, this task offers a lower-noise and more structured supervision signal. Ground-truth targets are typically available as binary labels or partial rankings, which reduces the influence of non-informative genes whose expression may fluctuate due to technical noise or unrelated biological variation. As a result, target gene identification provides a complementary and biologically grounded perspective for assessing the practical utility of virtual cell models.

    \subsection{Our Contributions}

    In this project, we make the following contributions:
    
    \begin{itemize}
        \item We reimplemented a more biologically informed set of evaluation metrics for the Virtual Cell Challenge (VCC) and applied them to a subset of 150 known gene perturbations, with a revised train/validation/test split. Using these metrics, we benchmarked the performance of two representative virtual cell models: STATE and scGPT.
        
        \item We adapted scGPT to leverage the improved VCC evaluation metrics and created scGPT-based models specifically for \textbf{target gene identification}, enabling a more biologically meaningful assessment of model predictions.
        
        \item We extended our evaluation beyond gene perturbations to drug perturbations and provide an exploratory study on the \textbf{Tahoe-100M} dataset, highlighting the challenges.
    \end{itemize}

    \section*{Author Contributions}

    \begin{itemize}
        \item \textbf{Anrui Wang}: Implemented scGPT experiments to fulfill the Virtual Cell Challenge (VCC) requirements, evaluated model performance, adapted scGPT to leverage the improved VCC evaluation metrics, and created scGPT-based models specifically for target gene identification, enabling a more biologically meaningful assessment of predictions.
        
        \item \textbf{Jiawen Dai}: Reimplemented a more biologically informed set of evaluation metrics for the Virtual Cell Challenge (VCC), conducted baseline experiments for VCC models, and extracted relevant data from the Tahoe-100M dataset.
        
        \item \textbf{Yiting Qi}: Implemented STATE experiments to fulfill the VCC requirements and evaluate performance, conducted studies on the Tahoe-100M dataset, and developed baseline models for target gene prediction on the Tahoe-100M dataset.
    \end{itemize}



    \section{Related Work}

    \subsection{Gene Perturbation Benchmarks}
    Standardized benchmarks are essential for evaluating virtual cell models. 
    The Virtual Cell Challenge (VCC) provides dedicated single-cell genetic perturbation datasets generated by silencing 300 selected genes in H1 human embryonic stem cells using CRISPR interference. 
    The data include approximately 300,000 single-cell RNA-seq profiles measured with 10x Genomics GEM-X Flex and Illumina sequencing. 
    For the challenge, the dataset is split into training (150 perturbations, ~183,000 cells), validation (50 perturbations), and final test (100 held-out perturbations). 
    Perturbations are categorized based on their effect sizes: strong (more than 100 differentially expressed genes), subtle (10-100 DEGs), and negligible (<10 DEGs). 
    This benchmark enables systematic assessment of transcriptome-wide prediction.
    
    The Norman dataset is another commonly used benchmark in single-cell perturbation modeling. 
    In scGPT, it was used for a reverse perturbation prediction task, where the model predicts the source of genetic perturbations given the resulting cell state. 
    For example, a subset of 20 genes is used to construct single- or double-gene perturbation combinations, yielding a closed candidate set of 210 perturbation conditions. 
    The model is fine-tuned on a subset of known perturbations and evaluated by retrieving the top-K candidate perturbations that best match the observed cell states.
    
    \subsection{State-of-the-art Models}
    In this work, we focus on two representative approaches for virtual cell modeling.

    \subsubsection{STATE}
    STATE (Single-cell Transformer for Adaptive Transcriptomic Effects) is a transformer-based model designed to predict transcriptomic responses to genetic, signaling, and chemical perturbations while accounting for cellular heterogeneity within and across experiments. 
    It leverages large-scale single-cell data, trained on over 100 million perturbed cells, to capture complex relationships between genes and accurately model perturbation effects.
    
    The model consists of two main modules:
    
    \begin{itemize}
        \item \textbf{State Embedding (SE)}: This module learns high-dimensional representations of single cells using self-supervised training. Each gene is first embedded using a protein language model (ESM2) and then processed via a Transformer to model gene-gene interactions. For each cell, the top high-expression genes are selected to form a sequence, augmented with expression-weighted embeddings. The output of a [CLS] token is combined with a dataset token ([DS]) to produce the final cell embedding vector.
    
        \item \textbf{State Transition (ST)}: This module learns how perturbations alter cell states through supervised training. The input includes embeddings of control cells, perturbation conditions, and batch information to account for technical variability. These are combined and passed through a Transformer backbone to predict perturbed gene expression profiles. The model is trained using a Maximum Mean Discrepancy (MMD) loss to align the predicted distribution with the observed distribution of perturbed cells, ensuring that the predicted cellular responses capture realistic biological variation.
    \end{itemize}
    
    STATE has been shown to improve the discrimination of perturbation effects in large datasets and effectively identify differentially expressed genes. Moreover, it can generalize to novel cellular contexts where perturbations were not observed during training, highlighting the advantages of large-scale, data-driven models for virtual cell modeling.
    
    \subsubsection{scGPT}
    
    
    \subsection{Drug Perturbation Datasets}
    Beyond gene-level perturbations, large-scale datasets such as \textbf{Tahoe-100M} provide systematic profiling of drug responses across diverse cell states. Tahoe-100M is currently the largest single-cell perturbation dataset, containing over 100 million cells sampled from 1,344 experimental conditions, including 380 chemical compounds applied at multiple concentrations across approximately 50 cancer cell lines and 14 experimental plates. 
    
    The dataset includes cell-level metadata such as experimental plate ID, cell cycle phase, and cell cycle scores (S\_score, G2M\_score), enabling more detailed analyses of cellular heterogeneity under chemical perturbations. These data allow evaluation of virtual cell models in pharmacological contexts and testing their generalization beyond single-gene interventions.

    
    \subsection{Connection to Our Work}
    Our work builds upon and integrates the methodologies of both STATE and scGPT for practical evaluation and target gene identification. Specifically:
    
    \begin{itemize}
        \item We utilize the \textbf{State Transition (ST)} module from STATE to predict transcriptomic responses, applied to a subset of 150 known gene perturbations from the VCC H1 perturbation dataset. We also implement a revised train/validation/test split to systematically benchmark model performance on these perturbations.
        
        \item Using \textbf{scGPT}, we finetune the model to leverage the improved VCC evaluation metrics, applied to the same 150 known perturbations with the revised data split. This enables a direct comparison of scGPT and STATE on the VCC benchmark under more biologically informed metrics.
        
        \item We further extend scGPT for \textbf{target gene identification}, creating scGPT-based models capable of ranking candidate genes by their likelihood of being true perturbation targets. For these downstream tasks, we incorporate the Norman dataset as a source of perturbation data to fine-tune and validate the model. 
        
        \item Finally, we conduct preliminary exploration on the \textbf{Tahoe-100M} drug perturbation dataset to assess the feasibility of applying scGPT to larger-scale pharmacological perturbations, although full target gene prediction on this dataset remains future work.
    \end{itemize}
    
    This progression illustrates the workflow of our study: starting from transcriptome-wide perturbation prediction using STATE’s ST module, benchmarking and finetuning scGPT with improved VCC metrics, and moving towards biologically meaningful downstream evaluation in target gene identification.


	
	
	\section{Methods}

	\subsection{Transcriptome-wide Perturbation Prediction}

    \subsubsection{STATE Implementation Pipeline}

    We implement the STATE model following the official open-source implementation released by the authors.
    In this work, we focus on the \textit{State Transition (ST)} module of STATE, which is responsible for predicting
    perturbation-induced transcriptomic responses given control cells and perturbation conditions.
    
    \paragraph{Data preprocessing.}
    We use the ARC Institute VCC competition support dataset (\texttt{competition\_support\_set}),
    which provides preprocessed single-cell RNA-seq data for H1 human embryonic stem cells.
    Gene expression values are transformed using a \texttt{log1p} normalization,
    which stabilizes variance and reduces the dominance of highly expressed genes.
    Control cells corresponding to non-targeting perturbations are retained and used as a reference state.
    
    \paragraph{Perturbation features.}
    Perturbation identities are represented using pretrained protein embeddings.
    Specifically, gene perturbations are encoded using ESM2-based perturbation feature vectors provided
    by the official STATE repository.
    These embeddings allow the model to incorporate prior biological information about gene identity
    without directly accessing expression-level supervision.
    
    \paragraph{Model architecture.}
    The ST module takes as input control cell expression profiles, perturbation embeddings, and batch embeddings
    to account for technical variability.
    All inputs are projected into a shared hidden space and processed by a Transformer backbone,
    which models how perturbations induce shifts in cellular state distributions.
    The output representations are mapped back to the gene expression space to generate predicted
    perturbed transcriptomes.

    \subsubsection{scGPT}

	
	
	\subsection{From Transcriptome-wide Predictions to Target Gene Identification} 

	
	
	\section{Experiments}
	
	\subsection{Transcriptome-wide Perturbation Prediction}
	
	\subsubsection{Dataset and Data Split}

    Instead of using the original VCC split, we re-split 150 gene perturbations into training, validation, and test sets at the perturbation level to evaluate generalization to unseen perturbations.
    
    Specifically, 64\% of perturbation genes are used for training, 16\% for validation, and the remaining 20\% (30 genes) form a held-out test set.
    Control (non-targeting) cells are included in all splits to provide a consistent reference state.
    Importantly, there is no overlap of perturbation genes between the training, validation, and test sets, ensuring that models are evaluated on entirely unseen perturbation targets.

    \subsubsection{Evaluation metrics: MAE, PDS, DES}

    \subsubsection{Experiment Setup}
    
    \subsubsection{Main Results}

    \subsection{Target Gene Identification}

    \section{Extending to Drug Perturbations: Tahoe-100M}
	
	\section{Discussion}
	
	\section{Conclusion}
	
	
	\section*{References}
	
	[1] 
	%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	
	
\end{document}\documentclass{article}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{Your Paper}
\author{You}

\begin{document}
\maketitle

\begin{abstract}
Your abstract.
\end{abstract}

\section{Introduction}

Your introduction goes here! Simply start writing your document and use the Recompile button to view the updated PDF preview. Examples of commonly used commands and features are listed below, to help you get started.

Once you're familiar with the editor, you can find various project settings in the Overleaf menu, accessed via the button in the very top left of the editor. To view tutorials, user guides, and further documentation, please visit our \href{https://www.overleaf.com/learn}{help library}, or head to our plans page to \href{https://www.overleaf.com/user/subscription/plans}{choose your plan}.

\section{Some examples to get started}

\subsection{How to create Sections and Subsections}

Simply use the section and subsection commands, as in this example document! With Overleaf, all the formatting and numbering is handled automatically according to the template you've chosen. If you're using the Visual Editor, you can also create new section and subsections via the buttons in the editor toolbar.

\subsection{How to include Figures}

First you have to upload the image file from your computer using the upload link in the file-tree menu. Then use the includegraphics command to include it in your document. Use the figure environment and the caption command to add a number and a caption to your figure. See the code for Figure \ref{fig:frog} in this section for an example.

Note that your figure will automatically be placed in the most appropriate place for it, given the surrounding text and taking into account other figures or tables that may be close by. You can find out more about adding images to your documents in this help article on \href{https://www.overleaf.com/learn/how-to/Including_images_on_Overleaf}{including images on Overleaf}.

\begin{figure}
\centering
\includegraphics[width=0.25\linewidth]{frog.jpg}
\caption{\label{fig:frog}This frog was uploaded via the file-tree menu.}
\end{figure}

\subsection{How to add Tables}

Use the table and tabular environments for basic tables --- see Table~\ref{tab:widgets}, for example. For more information, please see this help article on \href{https://www.overleaf.com/learn/latex/tables}{tables}.

\begin{table}
\centering
\begin{tabular}{l|r}
Item & Quantity \\\hline
Widgets & 42 \\
Gadgets & 13
\end{tabular}
\caption{\label{tab:widgets}An example table.}
\end{table}

\subsection{How to add Comments and Track Changes}

Comments can be added to your project by highlighting some text and clicking ``Add comment'' in the top right of the editor pane. To view existing comments, click on the Review menu in the toolbar above. To reply to a comment, click on the Reply button in the lower right corner of the comment. You can close the Review pane by clicking its name on the toolbar when you're done reviewing for the time being.

Track changes are available on all our \href{https://www.overleaf.com/user/subscription/plans}{premium plans}, and can be toggled on or off using the option at the top of the Review pane. Track changes allow you to keep track of every change made to the document, along with the person making the change.

\subsection{How to add Lists}

You can make lists with automatic numbering \dots

\begin{enumerate}
\item Like this,
\item and like this.
\end{enumerate}
\dots or bullet points \dots
\begin{itemize}
\item Like this,
\item and like this.
\end{itemize}

\subsection{How to write Mathematics}

\LaTeX{} is great at typesetting mathematics. Let $X_1, X_2, \ldots, X_n$ be a sequence of independent and identically distributed random variables with $\text{E}[X_i] = \mu$ and $\text{Var}[X_i] = \sigma^2 < \infty$, and let
\[S_n = \frac{X_1 + X_2 + \cdots + X_n}{n}
      = \frac{1}{n}\sum_{i}^{n} X_i\]
denote their mean. Then as $n$ approaches infinity, the random variables $\sqrt{n}(S_n - \mu)$ converge in distribution to a normal $\mathcal{N}(0, \sigma^2)$.


\subsection{How to change the margins and paper size}

Usually the template you're using will have the page margins and paper size set correctly for that use-case. For example, if you're using a journal article template provided by the journal publisher, that template will be formatted according to their requirements. In these cases, it's best not to alter the margins directly.

If however you're using a more general template, such as this one, and would like to alter the margins, a common way to do so is via the geometry package. You can find the geometry package loaded in the preamble at the top of this example file, and if you'd like to learn more about how to adjust the settings, please visit this help article on \href{https://www.overleaf.com/learn/latex/page_size_and_margins}{page size and margins}.

\subsection{How to change the document language and spell check settings}

Overleaf supports many different languages, including multiple different languages within one document.

To configure the document language, simply edit the option provided to the babel package in the preamble at the top of this example project. To learn more about the different options, please visit this help article on \href{https://www.overleaf.com/learn/latex/International_language_support}{international language support}.

To change the spell check language, simply open the Overleaf menu at the top left of the editor window, scroll down to the spell check setting, and adjust accordingly.

\subsection{How to add Citations and a References List}

You can simply upload a \verb|.bib| file containing your BibTeX entries, created with a tool such as JabRef. You can then cite entries from it, like this: \cite{greenwade93}. Just remember to specify a bibliography style, as well as the filename of the \verb|.bib|. You can find a \href{https://www.overleaf.com/help/97-how-to-include-a-bibliography-using-bibtex}{video tutorial here} to learn more about BibTeX.

If you have an \href{https://www.overleaf.com/user/subscription/plans}{upgraded account}, you can also import your Mendeley or Zotero library directly as a \verb|.bib| file, via the upload menu in the file-tree.

\subsection{Good luck!}

We hope you find Overleaf useful, and do take a look at our \href{https://www.overleaf.com/learn}{help library} for more tutorials and user guides! Please also let us know if you have any feedback using the \textbf{Contact us} link at the bottom of the Overleaf menu --- or use the contact form at \url{https://www.overleaf.com/contact}.

\bibliographystyle{alpha}
\bibliography{sample}

\end{document}
