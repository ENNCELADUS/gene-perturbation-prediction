{
  "overall": {
    "exact_hit@1": 0.0,
    "exact_hit@5": 0.0,
    "exact_hit@8": 0.0,
    "exact_hit@10": 0.0,
    "exact_hit@20": 0.0,
    "mrr": 0.0,
    "relevant_hit@1": 0.0,
    "relevant_hit@5": 0.034482758620689655,
    "relevant_hit@8": 0.10344827586206896,
    "relevant_hit@10": 0.13793103448275862,
    "relevant_hit@20": 0.27586206896551724,
    "ndcg@1": 0.0,
    "ndcg@5": 0.0,
    "ndcg@8": 0.0,
    "ndcg@10": 0.0,
    "ndcg@20": 0.0,
    "macro_hit@1": 0.0,
    "macro_hit@5": 0.0,
    "n_queries": 29,
    "n_in_pool": 29,
    "n_conditions": 29
  },
  "by_stratum": {
    "double_test": {
      "exact_hit@1": 0.0,
      "exact_hit@5": 0.0,
      "exact_hit@8": 0.0,
      "exact_hit@10": 0.0,
      "exact_hit@20": 0.0,
      "mrr": 0.0,
      "relevant_hit@1": 0.0,
      "relevant_hit@5": 0.034482758620689655,
      "relevant_hit@8": 0.10344827586206896,
      "relevant_hit@10": 0.13793103448275862,
      "relevant_hit@20": 0.27586206896551724,
      "ndcg@1": 0.0,
      "ndcg@5": 0.0,
      "ndcg@8": 0.0,
      "ndcg@10": 0.0,
      "ndcg@20": 0.0,
      "macro_hit@1": 0.0,
      "macro_hit@5": 0.0,
      "n_queries": 29,
      "n_in_pool": 29,
      "n_conditions": 29
    }
  },
  "n_test_conditions": 29,
  "n_evaluated": 29,
  "n_candidates": 236
}